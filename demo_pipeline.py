#!/usr/bin/env python3
"""
Streamlit Smart Kiosk v2

Logic: Detect Face ‚Üí Stop Stream ‚Üí Process
"""

import streamlit as st
import requests
import cv2
import numpy as np
import time
from datetime import datetime

st.set_page_config(page_title="Quick Face Kiosk", page_icon="‚ö°", layout="wide")
API_URL = "http://localhost:8000/api/v1"

def check_server():
    try:
        requests.get(f"{API_URL}/health", timeout=1)
        return True
    except:
        return False

def detect_only_local(frame):
    """Simple OpenCV detection just to check if face exists (Faster than API roundtrip)"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
    return len(faces) > 0, faces

def process_checkin(frame):
    """Send frame to server for recognition (simple endpoint)"""
    _, buf = cv2.imencode('.jpg', frame)
    try:
        # Use recognize_face - simple recognition endpoint
        resp = requests.post(f"{API_URL}/recognize_face", 
                           files={'file': ('f.jpg', buf.tobytes(), 'image/jpeg')},
                           params={'threshold': 0.5}, timeout=2)
        return resp.json()
    except:
        return None

def process_enroll(frame, uid, name):
    """Send frame to server for enrollment"""
    _, buf = cv2.imencode('.jpg', frame)
    try:
        resp = requests.post(f"{API_URL}/add_face",
                           files={'file': ('f.jpg', buf.tobytes(), 'image/jpeg')},
                           data={'user_id': uid, 'name': name}, timeout=5)
        return resp.json()
    except:
        return {'success': False, 'message': 'API Error'}

def main():
    st.title("‚ö° Quick Detect & Process")
    
    mode = st.radio("Ch·∫ø ƒë·ªô:", ["Ch·∫•m c√¥ng (Check-in)", "ƒêƒÉng k√Ω (Enrollment)"], horizontal=True)
    
    # Init session state
    if 'stop_stream' not in st.session_state:
        st.session_state['stop_stream'] = False
    
    col1, col2 = st.columns([1.5, 1])
    
    with col1:
        start = st.button("‚ñ∂Ô∏è B·∫ÆT ƒê·∫¶U", type="primary", use_container_width=True)
        video_place = st.empty()
        
    with col2:
        result_place = st.empty()
        
        # Enrollment inputs
        if "ƒêƒÉng k√Ω" in mode:
            st.divider()
            uid = st.text_input("User ID")
            name = st.text_input("Name")
            if not uid or not name:
                st.info("Nh·∫≠p th√¥ng tin ƒë·ªÉ ƒëƒÉng k√Ω")

    if start:
        if "ƒêƒÉng k√Ω" in mode and (not uid or not name):
            st.warning("Thi·∫øu th√¥ng tin User ID/Name")
            return
            
        cap = cv2.VideoCapture(0)
        st.session_state['stop_stream'] = False
        
        frame_count = 0
        process_frame_interval = 2  # Process every 2nd frame (50% reduction)
        status_text = st.empty()
        
        while not st.session_state['stop_stream']:
            ret, frame = cap.read()
            if not ret: break
            frame_count += 1
            
            # Show Feed (always display for smooth video)
            video_place.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
            status_text.text(f"ƒêang t√¨m khu√¥n m·∫∑t... Frame {frame_count}")
            
            # SKIP PROCESSING for alternate frames to reduce load
            if frame_count % process_frame_interval != 0:
                time.sleep(0.01)
                continue
            
            # --- LOGIC M·ªöI: DETECT LOCAL ‚Üí NH·∫¨N DI·ªÜN ‚Üí CH·ªà D·ª™NG KHI TH√ÄNH C√îNG ---
            has_face, faces = detect_only_local(frame)
            
            if has_face:
                # T√¨m th·∫•y m·∫∑t -> Th·ª≠ nh·∫≠n di·ªán TR∆Ø·ªöC
                status_text.info("üîç Ph√°t hi·ªán khu√¥n m·∫∑t! ƒêang nh·∫≠n di·ªán...")
                
                # Draw box on current frame
                temp_frame = frame.copy()
                for (x,y,w,h) in faces:
                    cv2.rectangle(temp_frame, (x,y), (x+w,y+h), (0,255,0), 2)
                video_place.image(cv2.cvtColor(temp_frame, cv2.COLOR_BGR2RGB), caption="ƒêang x·ª≠ l√Ω...", channels="RGB", use_container_width=True)
                
                # X·ª≠ l√Ω frame
                recognition_success = False
                
                if "Ch·∫•m c√¥ng" in mode:
                    res = process_checkin(frame)
                    if res and res.get('success'):
                        matches = res.get('matches', [])
                        
                        # Check if any match found
                        if matches:
                            # Get first match (highest similarity)
                            match = matches[0]
                            
                            if match.get('is_match'):
                                # TH√ÄNH C√îNG -> D·ª™NG
                                recognition_success = True
                                st.session_state['stop_stream'] = True
                                
                                user = match.get('name') or match.get('user_id')
                                similarity = match.get('similarity', 0)
                                
                                result_place.success(f"‚úÖ CH·∫§M C√îNG TH√ÄNH C√îNG!\nXin ch√†o: **{user}**\nSimilarity: {similarity:.2%}")
                                video_place.image(cv2.cvtColor(temp_frame, cv2.COLOR_BGR2RGB), caption="‚úÖ ƒê√£ nh·∫≠n di·ªán th√†nh c√¥ng!", channels="RGB", use_container_width=True)
                                st.balloons()
                            else:
                                # KH√îNG MATCH -> TI·∫æP T·ª§C QU√âT
                                similarity = match.get('similarity', 0)
                                status_text.warning(f"‚ö†Ô∏è Similarity qu√° th·∫•p ({similarity:.2%} < 50%). Ti·∫øp t·ª•c qu√©t...")
                        else:
                            # KH√îNG T√åM TH·∫§Y MATCH -> TI·∫æP T·ª§C
                            status_text.warning("‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c. Ti·∫øp t·ª•c qu√©t...")
                    else:
                        status_text.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t h·ª£p l·ªá. Ti·∫øp t·ª•c qu√©t...")
                        
                else: # Enrollment
                    res = process_enroll(frame, uid, name)
                    if res.get('success'):
                        # ƒêƒÇNG K√ù TH√ÄNH C√îNG -> D·ª™NG
                        recognition_success = True
                        st.session_state['stop_stream'] = True
                        result_place.success(f"‚úÖ ƒêƒÇNG K√ù TH√ÄNH C√îNG!\n{name} ({uid})")
                        video_place.image(cv2.cvtColor(temp_frame, cv2.COLOR_BGR2RGB), caption="‚úÖ ƒê√£ ƒëƒÉng k√Ω th√†nh c√¥ng!", channels="RGB", use_container_width=True)
                        st.balloons()
                    else:
                        # ƒêƒÇNG K√ù TH·∫§T B·∫†I -> TI·∫æP T·ª§C QU√âT
                        status_text.warning(f"‚ö†Ô∏è ƒêƒÉng k√Ω th·∫•t b·∫°i: {res.get('message')}. Ti·∫øp t·ª•c qu√©t...")
                
                # Ch·ªâ d·ª´ng camera n·∫øu th√†nh c√¥ng
                if recognition_success:
                    cap.release()
                    
            time.sleep(0.01) # Low latency loop
            
        if cap.isOpened():
            cap.release()

if __name__ == '__main__':
    main()
